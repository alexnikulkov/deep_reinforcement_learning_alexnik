{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple, deque, OrderedDict\n",
    "import torch\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from scipy import signal\n",
    "from torchviz import make_dot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_torch(a):\n",
    "    \"\"\"\n",
    "    Convert numpy array into a pytorch tensor and send to device\n",
    "    \"\"\"\n",
    "    return torch.from_numpy(a).float().to(device)\n",
    "\n",
    "\n",
    "def scale_weights(model, scale):\n",
    "    \"\"\"\n",
    "    Multiply all model weights by a given multiplier.\n",
    "    \"\"\"\n",
    "    for param in model.parameters():\n",
    "        param.data.copy_(param.data * scale)\n",
    "\n",
    "\n",
    "class ActorNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    An actor network which simultaneously prescribes an action to take as a fucntion of state.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, seed, hidden_sizes_list):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        \n",
    "        Inputs:\n",
    "            state_size (int): Dimension of each state.\n",
    "            action_size (int): Dimension of each action.\n",
    "            seed (int): Random seed.\n",
    "            hidden_sizes_list (list): The sizes of hidden layers in the network.\n",
    "        \"\"\"\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        model = OrderedDict([\n",
    "            ['fc_1', nn.Linear(state_size, hidden_sizes_list[0])],\n",
    "            ['relu_1', nn.ReLU()]\n",
    "        ])\n",
    "        for i in range(1, len(hidden_sizes_list)):\n",
    "            model['fc_{}'.format(i + 1)] = nn.Linear(hidden_sizes_list[i - 1], hidden_sizes_list[i])\n",
    "            model['relu_{}'.format(i + 1)] = nn.ReLU()\n",
    "        model['fc_output'] = nn.Linear(hidden_sizes_list[-1], action_size)\n",
    "        self.model = nn.Sequential(model)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\" Forward propagation through the network.\"\"\"\n",
    "        return self.tanh(self.model(state))\n",
    "\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    A critic network which predicts the action value for a state.\n",
    "    Action is inserted as an input to the last hidden layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, seed, hidden_sizes_list):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        \n",
    "        Inputs:\n",
    "            state_size (int): Dimension of each state.\n",
    "            action_size (int): Dimension of each action.\n",
    "            seed (int): Random seed.\n",
    "            hidden_sizes_list (list): The sizes of hidden layers in the network.\n",
    "        \"\"\"\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        model_first_part = OrderedDict([\n",
    "            ['fc_1', nn.Linear(state_size, hidden_sizes_list[0])],\n",
    "            ['relu_1', nn.ReLU()]\n",
    "        ])\n",
    "        self.model_first_part = nn.Sequential(model_first_part)\n",
    "        model_second_part = OrderedDict()\n",
    "        for i in range(1, len(hidden_sizes_list)):\n",
    "            model_second_part['fc_{}'.format(i + 1)] = nn.Linear(hidden_sizes_list[i - 1] + action_size * (i==1), hidden_sizes_list[i])\n",
    "            model_second_part['relu_{}'.format(i + 1)] = nn.ReLU()\n",
    "        self.model_second_part = nn.Sequential(model_second_part)\n",
    "        self.output_layer = nn.Linear(hidden_sizes_list[-1], 1)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        \"\"\" Forward propagation through the network.\"\"\"\n",
    "        x = self.model_first_part(state)\n",
    "        x = torch.cat([x, action], 1)\n",
    "        x = self.model_second_part(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "\n",
    "        Inputs:\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, states, actions, rewards, next_states, dones):\n",
    "        \"\"\"Add a set of new experiences to memory.\n",
    "        \n",
    "        Inputs:\n",
    "            states: Current state\n",
    "            actions: Action taken in the current state.\n",
    "            rewards: Reward received at the current step.\n",
    "            next_states: A state into which the transition occurs.\n",
    "            dones: An indicator of the transition learding into a terminal state.\n",
    "        \"\"\"\n",
    "        if states.ndim == 1:\n",
    "            es = [self.experience(states, actions, rewards, next_states, dones)]\n",
    "        else:\n",
    "            es = [self.experience(states[i], actions[i], rewards[i], next_states[i], dones[i]) for i in range(states.shape[0])]\n",
    "        for e in es:\n",
    "            self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, self.batch_size)\n",
    "\n",
    "        states = np_to_torch(np.vstack([e.state for e in experiences if e is not None]))\n",
    "        actions = np_to_torch(np.vstack([e.action for e in experiences if e is not None]))\n",
    "        rewards = np_to_torch(np.vstack([e.reward for e in experiences if e is not None]))\n",
    "        next_states = np_to_torch(np.vstack([e.next_state for e in experiences if e is not None]))\n",
    "        dones = np_to_torch(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8))\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUProcess():\n",
    "    \"\"\"\n",
    "    Orstein-Uhlenbeck process.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, theta, sigma, dims, mu=0.0):\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.dims = dims\n",
    "        self.mu = mu\n",
    "        self.values = np.ones(dims) * mu\n",
    "        \n",
    "    def sample(self):\n",
    "        self.values += self.theta * (self.mu - self.values) + self.sigma * np.random.normal(size=self.dims)\n",
    "        return self.values\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"\n",
    "    An RL agent which can interact with an environment and learn from replayed experiences.\n",
    "    Uses an actor-critic method for continuous actions (DDPG).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_instances, state_size, action_size, seed, actor_hidden_sizes_list, critic_hidden_sizes_list,\n",
    "                 num_iters_learn=1, update_every=4, batch_size=128, gamma=0.99, buffer_size=int(1e6),\n",
    "                 update_target_network_every=1, actor_lr0=1e-4, critic_lr0=1e-3,\n",
    "                 noise_theta=0.15, noise_sigma=0.2, noise_sigma_decay=1.0, weight_decay=0.0,\n",
    "                 actor_reg_loss_weight=0.0, random_seed=0):\n",
    "        \"\"\" Initialize an Agent object.\n",
    "        \n",
    "        Inputs:\n",
    "            num_instances (int): Number of actors running in parallel.\n",
    "            state_size (int): The dimensionality of the state space.\n",
    "            action_size (int): Number of possible actions an agent can take.\n",
    "            seed (int): Randomization seed.\n",
    "            actor_hidden_sizes_list (list): The sizes of hidden layers in the actor network.\n",
    "            critic_hidden_sizes_list (list): The sizes of hidden layers in the critic network.\n",
    "            num_iters_learn (int, optional): Number of iterations to take at each step towards the targets.\n",
    "            update_every (int, optional): How often the main networks are updated (default 1).\n",
    "            batch_size (int, optional): Batch size for each upate (default 64).\n",
    "            gamma (float, optional): Temporal discount coefficient (default 0.99).\n",
    "            buffer_size (int, optional): Maximum capacity of the replay buffer (default 1e6).\n",
    "            update_target_network_every (int, optional): How often to update the target network (default 1).\n",
    "            actor_lr0 (float, optional): Initial learning rate for the actor (default 1e-4).\n",
    "            critic_lr0 (float, optional): Initial learning rate for the critic (default 1e-3).\n",
    "            noise_theta (float): Parameter of Ornstein-Uhlenbeck noise process.\n",
    "            noise_sigma (float): Parameter of Ornstein-Uhlenbeck noise process.\n",
    "            noise_sigma_decay (float): Multiplier for noise_sigma (per episode).\n",
    "            weight_decay (float): Weight decay parameter for both actor and critic networks.\n",
    "            actor_reg_loss_weight (float): Weight placed on L2 norm of actions.\n",
    "            random_seed (int): Seed for pseudo-random numbers.\n",
    "        \"\"\"\n",
    "        self.num_instances = num_instances\n",
    "        self.action_size = action_size\n",
    "        self.state_size = state_size\n",
    "        self.seed = seed\n",
    "        self.num_iters_learn = num_iters_learn\n",
    "        self.update_every = update_every\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.actor_lr0 = actor_lr0\n",
    "        self.critic_lr0 = critic_lr0\n",
    "        self.update_target_network_every = update_target_network_every\n",
    "        self.actor_network_main = ActorNetwork(state_size, action_size, seed, actor_hidden_sizes_list).to(device)\n",
    "        self.actor_network_target = ActorNetwork(state_size, action_size, seed, actor_hidden_sizes_list).to(device)\n",
    "        scale_weights(self.actor_network_main, 0.01)\n",
    "        self.soft_update(self.actor_network_main, self.actor_network_target, tau=1.0)\n",
    "        self.actor_network_target.eval()\n",
    "        \n",
    "        self.critic_network_main = CriticNetwork(state_size, action_size, seed, critic_hidden_sizes_list).to(device)\n",
    "        self.critic_network_target = CriticNetwork(state_size, action_size, seed, critic_hidden_sizes_list).to(device)\n",
    "        scale_weights(self.critic_network_main, 0.01)\n",
    "        self.soft_update(self.critic_network_main, self.critic_network_target, tau=1.0)\n",
    "        self.critic_network_target.eval()\n",
    "        \n",
    "        self.actor_optimizer = optim.Adam(self.actor_network_main.parameters(), lr=actor_lr0, weight_decay=weight_decay)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_network_main.parameters(), lr=critic_lr0, weight_decay=weight_decay)\n",
    "        self.actor_reg_loss_weight = actor_reg_loss_weight\n",
    "        self.actor_reg_loss_fn = lambda x: F.mse_loss(x, torch.zeros_like(x))\n",
    "        \n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, buffer_size, batch_size, seed)\n",
    "        # Initialize time step (for updating every \"update_every\" steps)\n",
    "        self.t_step = 0\n",
    "        # Initialize OU noise\n",
    "        self.noise = OUProcess(theta=noise_theta, sigma=noise_sigma, dims=(num_instances, action_size))\n",
    "        self.noise_sigma_decay = noise_sigma_decay\n",
    "\n",
    "    def step(self, states, actions, rewards, next_states, dones):       \n",
    "        \"\"\"\n",
    "        Process a vector of state changes.\n",
    "        Periodically learn (update network) if enough experiences are available in the replay buffer.\n",
    "        \n",
    "        Inputs:\n",
    "            states: Current state\n",
    "            actions: Action taken in the current state.\n",
    "            rewards: Reward received at the current step.\n",
    "            next_states: A state into which the transition occurs.\n",
    "            dones: An indicator of the transition learding into a terminal state.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Save experience in replay memory\n",
    "        self.memory.add(states, actions, rewards, next_states, dones)\n",
    " \n",
    "        self.t_step += 1\n",
    "        if self.t_step % self.update_every == 0: # Learn every \"update_every\" time steps.\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(self.memory) > self.batch_size:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, self.gamma)\n",
    "        \n",
    "               \n",
    "    def act(self, states):\n",
    "        \"\"\"Returns actions for given states as per current policy.\n",
    "        \n",
    "        Inputs:\n",
    "            states (array_like): current states\n",
    "            eps (float): epsilon, for epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        states = torch.from_numpy(states).float().to(device)\n",
    "        self.actor_network_main.eval()\n",
    "        with torch.no_grad():\n",
    "            actions = self.actor_network_main(states).cpu().data.numpy()\n",
    "        self.actor_network_main.train()\n",
    "        return np.tanh(np.arctanh(actions) + self.noise.sample())\n",
    "#         return np.clip(actions + self.noise.sample(), -1, 1)\n",
    "\n",
    "                \n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update value parameters using given batch of experience tuples.\n",
    "\n",
    "        Inputs:\n",
    "            experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        \n",
    "        for _ in range(self.num_iters_learn):\n",
    "            # get targets for the critic network\n",
    "            with torch.no_grad():\n",
    "                actor_target_next_actions = self.actor_network_target(next_states)\n",
    "                Q_targets_next = self.critic_network_target(next_states, actor_target_next_actions)\n",
    "                critic_targets = (rewards + gamma * Q_targets_next * (1 - dones)).squeeze()\n",
    "            \n",
    "            # update critic\n",
    "            critic_predictions = self.critic_network_main(states, actions).squeeze()\n",
    "            critic_loss = F.mse_loss(critic_predictions, critic_targets)\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            self.critic_optimizer.step()\n",
    "            \n",
    "            # update actor\n",
    "            actor_proposed_actions = self.actor_network_main(states)\n",
    "            actor_objective = self.critic_network_main(states, actor_proposed_actions).mean()\n",
    "            actor_loss = -actor_objective + self.actor_reg_loss_weight * self.actor_reg_loss_fn(actor_proposed_actions)\n",
    "            self.actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "        \n",
    "        if self.t_step % self.update_target_network_every == 0:\n",
    "            self.soft_update(self.critic_network_main, self.critic_network_target, 1e-3)\n",
    "            self.soft_update(self.actor_network_main, self.actor_network_target, 1e-3)\n",
    "\n",
    "    def soft_update(self, main_model, target_model, tau=1e-3):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Inputs:\n",
    "            main_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter\n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), main_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:125: RuntimeWarning: divide by zero encountered in arctanh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tCurrent Score: 0.38\tAverage Score: 0.38, episode took 12.35 seconds\n",
      "Episode 2\tCurrent Score: 0.25\tAverage Score: 0.32, episode took 11.96 seconds\n",
      "Episode 3\tCurrent Score: 0.63\tAverage Score: 0.42, episode took 12.56 seconds\n",
      "Episode 4\tCurrent Score: 0.59\tAverage Score: 0.46, episode took 12.48 seconds\n",
      "Episode 5\tCurrent Score: 0.47\tAverage Score: 0.46, episode took 12.12 seconds\n",
      "Episode 6\tCurrent Score: 0.52\tAverage Score: 0.47, episode took 12.49 seconds\n",
      "Episode 7\tCurrent Score: 1.02\tAverage Score: 0.55, episode took 14.09 seconds\n",
      "Episode 8\tCurrent Score: 1.12\tAverage Score: 0.62, episode took 14.38 seconds\n",
      "Episode 9\tCurrent Score: 1.06\tAverage Score: 0.67, episode took 14.27 seconds\n",
      "Episode 10\tCurrent Score: 1.49\tAverage Score: 0.75, episode took 14.26 seconds\n",
      "Episode 11\tCurrent Score: 1.76\tAverage Score: 0.85, episode took 14.28 seconds\n",
      "Episode 12\tCurrent Score: 2.13\tAverage Score: 0.95, episode took 14.33 seconds\n",
      "Episode 13\tCurrent Score: 2.45\tAverage Score: 1.07, episode took 14.28 seconds\n",
      "Episode 14\tCurrent Score: 3.87\tAverage Score: 1.27, episode took 14.36 seconds\n",
      "Episode 15\tCurrent Score: 4.33\tAverage Score: 1.47, episode took 14.28 seconds\n",
      "Episode 16\tCurrent Score: 4.32\tAverage Score: 1.65, episode took 14.36 seconds\n",
      "Episode 17\tCurrent Score: 5.04\tAverage Score: 1.85, episode took 14.70 seconds\n",
      "Episode 18\tCurrent Score: 4.86\tAverage Score: 2.02, episode took 15.08 seconds\n",
      "Episode 19\tCurrent Score: 5.46\tAverage Score: 2.20, episode took 15.08 seconds\n",
      "Episode 20\tCurrent Score: 5.16\tAverage Score: 2.35, episode took 15.08 seconds\n",
      "Episode 21\tCurrent Score: 6.56\tAverage Score: 2.55, episode took 15.10 seconds\n",
      "Episode 22\tCurrent Score: 7.90\tAverage Score: 2.79, episode took 15.10 seconds\n",
      "Episode 23\tCurrent Score: 10.91\tAverage Score: 3.14, episode took 15.08 seconds\n",
      "Episode 24\tCurrent Score: 9.42\tAverage Score: 3.40, episode took 15.08 seconds\n",
      "Episode 25\tCurrent Score: 10.51\tAverage Score: 3.69, episode took 15.12 seconds\n",
      "Episode 26\tCurrent Score: 13.38\tAverage Score: 4.06, episode took 15.16 seconds\n",
      "Episode 27\tCurrent Score: 20.13\tAverage Score: 4.66, episode took 15.11 seconds\n",
      "Episode 28\tCurrent Score: 26.75\tAverage Score: 5.45, episode took 15.10 seconds\n",
      "Episode 29\tCurrent Score: 28.78\tAverage Score: 6.25, episode took 15.12 seconds\n",
      "Episode 30\tCurrent Score: 24.89\tAverage Score: 6.87, episode took 15.10 seconds\n",
      "Episode 31\tCurrent Score: 31.52\tAverage Score: 7.67, episode took 15.10 seconds\n",
      "Episode 32\tCurrent Score: 36.88\tAverage Score: 8.58, episode took 15.11 seconds\n",
      "Episode 33\tCurrent Score: 38.50\tAverage Score: 9.49, episode took 15.10 seconds\n",
      "Episode 34\tCurrent Score: 38.02\tAverage Score: 10.33, episode took 15.14 seconds\n",
      "Episode 35\tCurrent Score: 38.62\tAverage Score: 11.13, episode took 15.11 seconds\n",
      "Episode 36\tCurrent Score: 38.69\tAverage Score: 11.90, episode took 15.10 seconds\n",
      "Episode 37\tCurrent Score: 38.99\tAverage Score: 12.63, episode took 15.10 seconds\n",
      "Episode 38\tCurrent Score: 39.17\tAverage Score: 13.33, episode took 15.13 seconds\n",
      "Episode 39\tCurrent Score: 38.92\tAverage Score: 13.99, episode took 15.11 seconds\n",
      "Episode 40\tCurrent Score: 38.67\tAverage Score: 14.60, episode took 15.16 seconds\n",
      "Episode 41\tCurrent Score: 38.42\tAverage Score: 15.18, episode took 15.15 seconds\n",
      "Episode 42\tCurrent Score: 39.17\tAverage Score: 15.76, episode took 15.12 seconds\n",
      "Episode 43\tCurrent Score: 38.93\tAverage Score: 16.29, episode took 15.09 seconds\n",
      "Episode 44\tCurrent Score: 38.76\tAverage Score: 16.80, episode took 15.20 seconds\n",
      "Episode 45\tCurrent Score: 39.17\tAverage Score: 17.30, episode took 15.45 seconds\n",
      "Episode 46\tCurrent Score: 38.92\tAverage Score: 17.77, episode took 15.23 seconds\n",
      "Episode 47\tCurrent Score: 38.89\tAverage Score: 18.22, episode took 15.09 seconds\n",
      "Episode 48\tCurrent Score: 38.41\tAverage Score: 18.64, episode took 15.15 seconds\n",
      "Episode 49\tCurrent Score: 38.86\tAverage Score: 19.05, episode took 15.13 seconds\n",
      "Episode 50\tCurrent Score: 38.31\tAverage Score: 19.44, episode took 15.24 seconds\n",
      "Episode 51\tCurrent Score: 38.42\tAverage Score: 19.81, episode took 15.22 seconds\n",
      "Episode 52\tCurrent Score: 38.27\tAverage Score: 20.17, episode took 15.18 seconds\n",
      "Episode 53\tCurrent Score: 38.58\tAverage Score: 20.51, episode took 15.14 seconds\n",
      "Episode 54\tCurrent Score: 38.48\tAverage Score: 20.85, episode took 15.22 seconds\n",
      "Episode 55\tCurrent Score: 38.44\tAverage Score: 21.17, episode took 15.21 seconds\n",
      "Episode 56\tCurrent Score: 38.05\tAverage Score: 21.47, episode took 15.26 seconds\n",
      "Episode 57\tCurrent Score: 36.65\tAverage Score: 21.73, episode took 15.12 seconds\n",
      "Episode 58\tCurrent Score: 38.03\tAverage Score: 22.02, episode took 15.25 seconds\n",
      "Episode 59\tCurrent Score: 36.63\tAverage Score: 22.26, episode took 15.30 seconds\n",
      "Episode 60\tCurrent Score: 37.04\tAverage Score: 22.51, episode took 15.21 seconds\n",
      "Episode 61\tCurrent Score: 38.20\tAverage Score: 22.77, episode took 15.50 seconds\n",
      "Episode 62\tCurrent Score: 35.43\tAverage Score: 22.97, episode took 15.23 seconds\n",
      "Episode 63\tCurrent Score: 36.45\tAverage Score: 23.18, episode took 15.15 seconds\n",
      "Episode 64\tCurrent Score: 38.69\tAverage Score: 23.43, episode took 15.15 seconds\n",
      "Episode 65\tCurrent Score: 36.71\tAverage Score: 23.63, episode took 15.17 seconds\n",
      "Episode 66\tCurrent Score: 37.32\tAverage Score: 23.84, episode took 15.90 seconds\n",
      "Episode 67\tCurrent Score: 36.78\tAverage Score: 24.03, episode took 15.91 seconds\n",
      "Episode 68\tCurrent Score: 35.24\tAverage Score: 24.20, episode took 16.03 seconds\n",
      "Episode 69\tCurrent Score: 34.96\tAverage Score: 24.35, episode took 16.05 seconds\n",
      "Episode 70\tCurrent Score: 35.91\tAverage Score: 24.52, episode took 15.80 seconds\n",
      "Episode 71\tCurrent Score: 37.20\tAverage Score: 24.70, episode took 16.05 seconds\n",
      "Episode 72\tCurrent Score: 34.73\tAverage Score: 24.84, episode took 15.94 seconds\n",
      "Episode 73\tCurrent Score: 37.92\tAverage Score: 25.02, episode took 15.75 seconds\n",
      "Episode 74\tCurrent Score: 37.57\tAverage Score: 25.18, episode took 15.64 seconds\n",
      "Episode 75\tCurrent Score: 36.66\tAverage Score: 25.34, episode took 15.71 seconds\n",
      "Episode 76\tCurrent Score: 36.93\tAverage Score: 25.49, episode took 15.27 seconds\n",
      "Episode 77\tCurrent Score: 36.21\tAverage Score: 25.63, episode took 15.35 seconds\n",
      "Episode 78\tCurrent Score: 37.24\tAverage Score: 25.78, episode took 15.58 seconds\n",
      "Episode 79\tCurrent Score: 37.92\tAverage Score: 25.93, episode took 15.44 seconds\n",
      "Episode 80\tCurrent Score: 38.28\tAverage Score: 26.09, episode took 15.37 seconds\n",
      "Episode 81\tCurrent Score: 38.84\tAverage Score: 26.24, episode took 15.40 seconds\n",
      "Episode 82\tCurrent Score: 38.12\tAverage Score: 26.39, episode took 15.28 seconds\n",
      "Episode 83\tCurrent Score: 38.48\tAverage Score: 26.53, episode took 15.37 seconds\n",
      "Episode 84\tCurrent Score: 38.40\tAverage Score: 26.68, episode took 15.23 seconds\n",
      "Episode 85\tCurrent Score: 36.76\tAverage Score: 26.79, episode took 15.38 seconds\n",
      "Episode 86\tCurrent Score: 38.15\tAverage Score: 26.93, episode took 15.49 seconds\n",
      "Episode 87\tCurrent Score: 37.28\tAverage Score: 27.05, episode took 15.27 seconds\n",
      "Episode 88\tCurrent Score: 36.96\tAverage Score: 27.16, episode took 15.17 seconds\n",
      "Episode 89\tCurrent Score: 37.76\tAverage Score: 27.28, episode took 15.21 seconds\n",
      "Episode 90\tCurrent Score: 35.86\tAverage Score: 27.37, episode took 15.23 seconds\n",
      "Episode 91\tCurrent Score: 35.89\tAverage Score: 27.47, episode took 15.26 seconds\n",
      "Episode 92\tCurrent Score: 34.95\tAverage Score: 27.55, episode took 15.22 seconds\n",
      "Episode 93\tCurrent Score: 36.87\tAverage Score: 27.65, episode took 15.26 seconds\n",
      "Episode 94\tCurrent Score: 35.59\tAverage Score: 27.73, episode took 15.23 seconds\n",
      "Episode 95\tCurrent Score: 37.76\tAverage Score: 27.84, episode took 15.38 seconds\n",
      "Episode 96\tCurrent Score: 37.25\tAverage Score: 27.94, episode took 15.22 seconds\n",
      "Episode 97\tCurrent Score: 35.57\tAverage Score: 28.01, episode took 15.30 seconds\n",
      "Episode 98\tCurrent Score: 38.19\tAverage Score: 28.12, episode took 15.16 seconds\n",
      "Episode 99\tCurrent Score: 38.27\tAverage Score: 28.22, episode took 15.32 seconds\n",
      "Episode 100\tCurrent Score: 38.70\tAverage Score: 28.33, episode took 15.29 seconds\n",
      "Episode 101\tCurrent Score: 37.84\tAverage Score: 28.70, episode took 15.60 seconds\n",
      "Episode 102\tCurrent Score: 37.50\tAverage Score: 29.07, episode took 15.28 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 103\tCurrent Score: 34.44\tAverage Score: 29.41, episode took 15.30 seconds\n",
      "Episode 104\tCurrent Score: 33.85\tAverage Score: 29.74, episode took 15.20 seconds\n",
      "Episode 105\tCurrent Score: 36.50\tAverage Score: 30.10, episode took 15.33 seconds\n",
      "\n",
      "Environment solved in 5 episodes!\tAverage Score: 30.10\n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Reacher_20.app')\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "num_agents = len(env_info.agents)\n",
    "action_size = brain.vector_action_space_size\n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "\n",
    "agent = Agent(num_instances=num_agents,\n",
    "              state_size=state_size,\n",
    "              action_size=action_size,\n",
    "              seed=0,\n",
    "              actor_hidden_sizes_list=[256, 128],\n",
    "              critic_hidden_sizes_list=[256, 128],\n",
    "              gamma=0.99,\n",
    "              num_iters_learn=1,\n",
    "              actor_lr0=1e-4,\n",
    "              critic_lr0=1e-4,\n",
    "              weight_decay=1e-6,\n",
    "              actor_reg_loss_weight=0.0,\n",
    "              update_every=1,\n",
    "              noise_sigma=0.2,\n",
    "              noise_sigma_decay=0.99,\n",
    "              buffer_size=int(1e5),\n",
    "              batch_size=128)\n",
    "scores = []\n",
    "\n",
    "def ddqn(env, agent, scores, n_episodes=150, max_t=10000, save_every=10,\n",
    "        lr_decay_episode=0.996, actor_min_lr = 3e-7, critic_min_lr = 3e-6):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        save_every (int): How often to save the checkpoints\n",
    "        lr_decay_episode (float): Learning rate decay multiplier (per episode)\n",
    "        actor_min_lr (float): Minimum actor learning rate (capped at the bottom at this value)\n",
    "        critic_min_lr (float): Minimum critic learning rate (capped at the bottom at this value)\n",
    "    \"\"\"\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    hundred_episodes_start_time = time.time()\n",
    "    solved = False\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        for param_group in agent.actor_optimizer.param_groups:\n",
    "            # adjust actor learning rate\n",
    "            param_group['lr'] = max(agent.actor_lr0 * lr_decay_episode**i_episode, actor_min_lr)\n",
    "        for param_group in agent.critic_optimizer.param_groups:\n",
    "            # adjust critic learning rate\n",
    "            param_group['lr'] = max(agent.critic_lr0 * lr_decay_episode**i_episode, critic_min_lr)\n",
    "        # reduce action noise variance\n",
    "        agent.noise.sigma *= agent.noise_sigma_decay\n",
    "        episode_start_time = time.time()\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        states = env_info.vector_observations            # get the current state\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[env.brain_names[0]]        # send the actions to the environment\n",
    "            next_states = env_info.vector_observations   # get the next states\n",
    "            rewards = env_info.rewards                   # get the reward\n",
    "            dones = env_info.local_done                  # see if episode has finished\n",
    "            score += np.mean(rewards)                                # update the score\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "            states = next_states                             # roll over the state to next time step\n",
    "            if np.any(dones):                                       # exit loop if episode finished\n",
    "                break\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        episode_end_time = time.time()\n",
    "        print('\\rEpisode {}\\tCurrent Score: {:.2f}\\tAverage Score: {:.2f}, episode took {:.2f} seconds'.format(i_episode,\n",
    "            score, np.mean(scores_window), episode_end_time - episode_start_time))\n",
    "        if i_episode % save_every == 0:\n",
    "            hundred_episodes_end_time = time.time()\n",
    "            torch.save(agent.actor_network_main.state_dict(), 'checkpoints/checkpoint_actor_{}.pth'.format(i_episode))\n",
    "            torch.save(agent.critic_network_main.state_dict(), 'checkpoints/checkpoint_critic_{}.pth'.format(i_episode))\n",
    "            hundred_episodes_start_time = time.time()\n",
    "        if (np.mean(scores_window) >= 30.0) & ~solved:\n",
    "            solved = True\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100,\\\n",
    "                np.mean(scores_window)))\n",
    "            torch.save(agent.actor_network_main.state_dict(), 'checkpoints/final_checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_network_main.state_dict(), 'checkpoints/final_checkpoint_critic.pth')\n",
    "            break\n",
    "            \n",
    "ddqn(env, agent, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"454pt\" height=\"492pt\"\n",
       " viewBox=\"0.00 0.00 454.29 492.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 488)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-488 450.29,-488 450.29,4 -4,4\"/>\n",
       "<!-- 4927650392 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>4927650392</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"270.291,-20 166.334,-20 166.334,0 270.291,0 270.291,-20\"/>\n",
       "<text text-anchor=\"middle\" x=\"218.3125\" y=\"-6.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 4927649496 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>4927649496</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"140.6373,-88 41.9877,-88 41.9877,-56 140.6373,-56 140.6373,-88\"/>\n",
       "<text text-anchor=\"middle\" x=\"91.3125\" y=\"-74.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">output_layer.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"91.3125\" y=\"-62.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n",
       "</g>\n",
       "<!-- 4927649496&#45;&gt;4927650392 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>4927649496&#45;&gt;4927650392</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M124.3487,-55.8721C144.2165,-46.1728 169.2986,-33.928 188.5504,-24.5295\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.3047,-27.568 197.7556,-20.0357 187.2338,-21.2775 190.3047,-27.568\"/>\n",
       "</g>\n",
       "<!-- 4927649720 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>4927649720</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"278.1137,-82 158.5113,-82 158.5113,-62 278.1137,-62 278.1137,-82\"/>\n",
       "<text text-anchor=\"middle\" x=\"218.3125\" y=\"-68.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ThresholdBackward0</text>\n",
       "</g>\n",
       "<!-- 4927649720&#45;&gt;4927650392 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>4927649720&#45;&gt;4927650392</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M218.3125,-61.762C218.3125,-53.185 218.3125,-40.6836 218.3125,-30.1154\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"221.8126,-30.0475 218.3125,-20.0475 214.8126,-30.0476 221.8126,-30.0475\"/>\n",
       "</g>\n",
       "<!-- 4927650560 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4927650560</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"267.291,-150 163.334,-150 163.334,-130 267.291,-130 267.291,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"215.3125\" y=\"-136.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 4927650560&#45;&gt;4927649720 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4927650560&#45;&gt;4927649720</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M215.7552,-129.9664C216.1894,-120.1231 216.8642,-104.827 217.4117,-92.4189\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"220.9238,-92.2194 217.868,-82.0748 213.9306,-91.9108 220.9238,-92.2194\"/>\n",
       "</g>\n",
       "<!-- 4927650728 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4927650728</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"156.4379,-224 .1871,-224 .1871,-192 156.4379,-192 156.4379,-224\"/>\n",
       "<text text-anchor=\"middle\" x=\"78.3125\" y=\"-210.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">model_second_part.fc_2.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"78.3125\" y=\"-198.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (128)</text>\n",
       "</g>\n",
       "<!-- 4927650728&#45;&gt;4927650560 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>4927650728&#45;&gt;4927650560</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M110.7796,-191.8849C133.5254,-180.5951 163.6812,-165.6272 185.7564,-154.6702\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"187.5743,-157.6753 194.9755,-150.0943 184.4621,-151.4052 187.5743,-157.6753\"/>\n",
       "</g>\n",
       "<!-- 4927649888 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4927649888</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"256.1217,-218 174.5033,-218 174.5033,-198 256.1217,-198 256.1217,-218\"/>\n",
       "<text text-anchor=\"middle\" x=\"215.3125\" y=\"-204.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CatBackward</text>\n",
       "</g>\n",
       "<!-- 4927649888&#45;&gt;4927650560 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4927649888&#45;&gt;4927650560</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M215.3125,-197.9664C215.3125,-188.1231 215.3125,-172.827 215.3125,-160.4189\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"218.8126,-160.0748 215.3125,-150.0748 211.8126,-160.0748 218.8126,-160.0748\"/>\n",
       "</g>\n",
       "<!-- 4927648768 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>4927648768</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"258.1137,-286 138.5113,-286 138.5113,-266 258.1137,-266 258.1137,-286\"/>\n",
       "<text text-anchor=\"middle\" x=\"198.3125\" y=\"-272.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ThresholdBackward0</text>\n",
       "</g>\n",
       "<!-- 4927648768&#45;&gt;4927649888 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4927648768&#45;&gt;4927649888</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M200.8209,-265.9664C203.3068,-256.0227 207.1839,-240.5143 210.3025,-228.04\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"213.7639,-228.6251 212.7938,-218.0748 206.9729,-226.9273 213.7639,-228.6251\"/>\n",
       "</g>\n",
       "<!-- 4927648712 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>4927648712</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"250.291,-348 146.334,-348 146.334,-328 250.291,-328 250.291,-348\"/>\n",
       "<text text-anchor=\"middle\" x=\"198.3125\" y=\"-334.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 4927648712&#45;&gt;4927648768 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>4927648712&#45;&gt;4927648768</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M198.3125,-327.762C198.3125,-319.185 198.3125,-306.6836 198.3125,-296.1154\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"201.8126,-296.0475 198.3125,-286.0475 194.8126,-296.0476 201.8126,-296.0475\"/>\n",
       "</g>\n",
       "<!-- 4927648880 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>4927648880</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"207.2891,-416 65.3359,-416 65.3359,-384 207.2891,-384 207.2891,-416\"/>\n",
       "<text text-anchor=\"middle\" x=\"136.3125\" y=\"-402.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">model_first_part.fc_1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"136.3125\" y=\"-390.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256)</text>\n",
       "</g>\n",
       "<!-- 4927648880&#45;&gt;4927648712 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>4927648880&#45;&gt;4927648712</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M152.6023,-383.7102C161.2601,-375.0524 171.9107,-364.4018 180.7525,-355.56\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"183.3651,-357.8972 187.9613,-348.3512 178.4153,-352.9474 183.3651,-357.8972\"/>\n",
       "</g>\n",
       "<!-- 4927649104 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>4927649104</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"297.2871,-410 225.3379,-410 225.3379,-390 297.2871,-390 297.2871,-410\"/>\n",
       "<text text-anchor=\"middle\" x=\"261.3125\" y=\"-396.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 4927649104&#45;&gt;4927648712 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>4927649104&#45;&gt;4927648712</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M250.9093,-389.762C241.3683,-380.3724 227.0483,-366.2797 215.7583,-355.1688\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"218.1045,-352.5672 208.5221,-348.0475 213.1945,-357.5564 218.1045,-352.5672\"/>\n",
       "</g>\n",
       "<!-- 4927649048 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>4927649048</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"339.1194,-484 183.5056,-484 183.5056,-452 339.1194,-452 339.1194,-484\"/>\n",
       "<text text-anchor=\"middle\" x=\"261.3125\" y=\"-470.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">model_first_part.fc_1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"261.3125\" y=\"-458.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256, 33)</text>\n",
       "</g>\n",
       "<!-- 4927649048&#45;&gt;4927649104 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>4927649048&#45;&gt;4927649104</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M261.3125,-451.8849C261.3125,-442.5254 261.3125,-430.6379 261.3125,-420.6036\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"264.8126,-420.2954 261.3125,-410.2954 257.8126,-420.2954 264.8126,-420.2954\"/>\n",
       "</g>\n",
       "<!-- 4927649608 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>4927649608</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"380.2871,-218 308.3379,-218 308.3379,-198 380.2871,-198 380.2871,-218\"/>\n",
       "<text text-anchor=\"middle\" x=\"344.3125\" y=\"-204.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 4927649608&#45;&gt;4927650560 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>4927649608&#45;&gt;4927650560</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M325.2781,-197.9664C303.6514,-186.5662 268.1496,-167.8521 243.3531,-154.7811\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"244.9033,-151.6418 234.425,-150.0748 241.6391,-157.8341 244.9033,-151.6418\"/>\n",
       "</g>\n",
       "<!-- 4927649440 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>4927649440</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"446.2676,-292 276.3574,-292 276.3574,-260 446.2676,-260 446.2676,-292\"/>\n",
       "<text text-anchor=\"middle\" x=\"361.3125\" y=\"-278.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">model_second_part.fc_2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"361.3125\" y=\"-266.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (128, 260)</text>\n",
       "</g>\n",
       "<!-- 4927649440&#45;&gt;4927649608 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>4927649440&#45;&gt;4927649608</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M357.2837,-259.8849C354.9187,-250.4247 351.908,-238.382 349.3826,-228.2806\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"352.7073,-227.1479 346.8864,-218.2954 345.9163,-228.8457 352.7073,-227.1479\"/>\n",
       "</g>\n",
       "<!-- 4927649552 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>4927649552</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"374.2871,-82 302.3379,-82 302.3379,-62 374.2871,-62 374.2871,-82\"/>\n",
       "<text text-anchor=\"middle\" x=\"338.3125\" y=\"-68.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 4927649552&#45;&gt;4927650392 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>4927649552&#45;&gt;4927650392</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M318.7654,-61.9006C299.24,-51.8125 269.0162,-36.1969 246.8186,-24.7281\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"248.3421,-21.5758 237.8513,-20.095 245.129,-27.7948 248.3421,-21.5758\"/>\n",
       "</g>\n",
       "<!-- 4927649328 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>4927649328</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"396.9673,-156 285.6577,-156 285.6577,-124 396.9673,-124 396.9673,-156\"/>\n",
       "<text text-anchor=\"middle\" x=\"341.3125\" y=\"-142.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">output_layer.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"341.3125\" y=\"-130.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1, 128)</text>\n",
       "</g>\n",
       "<!-- 4927649328&#45;&gt;4927649552 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>4927649328&#45;&gt;4927649552</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M340.6015,-123.8849C340.1886,-114.5254 339.6642,-102.6379 339.2215,-92.6036\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"342.7041,-92.1314 338.7667,-82.2954 335.711,-92.44 342.7041,-92.1314\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x125b5f9e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = agent.critic_network_main\n",
    "make_dot(model(torch.randn(1,33), torch.randn(1,4)), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"397pt\" height=\"492pt\"\n",
       " viewBox=\"0.00 0.00 396.98 492.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 488)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-488 392.9795,-488 392.9795,4 -4,4\"/>\n",
       "<!-- 4927490928 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>4927490928</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"239.1213,-20 150.1931,-20 150.1931,0 239.1213,0 239.1213,-20\"/>\n",
       "<text text-anchor=\"middle\" x=\"194.6572\" y=\"-6.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TanhBackward</text>\n",
       "</g>\n",
       "<!-- 4927649664 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>4927649664</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"246.6357,-76 142.6787,-76 142.6787,-56 246.6357,-56 246.6357,-76\"/>\n",
       "<text text-anchor=\"middle\" x=\"194.6572\" y=\"-62.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 4927649664&#45;&gt;4927490928 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>4927649664&#45;&gt;4927490928</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M194.6572,-55.9883C194.6572,-48.9098 194.6572,-39.1714 194.6572,-30.4779\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"198.1573,-30.3038 194.6572,-20.3039 191.1573,-30.3039 198.1573,-30.3038\"/>\n",
       "</g>\n",
       "<!-- 4927648992 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>4927648992</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"117.4721,-144 -.1576,-144 -.1576,-112 117.4721,-112 117.4721,-144\"/>\n",
       "<text text-anchor=\"middle\" x=\"58.6572\" y=\"-130.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">model.fc_output.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"58.6572\" y=\"-118.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (4)</text>\n",
       "</g>\n",
       "<!-- 4927648992&#45;&gt;4927649664 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>4927648992&#45;&gt;4927649664</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M94.0346,-111.8721C115.5047,-102.0843 142.661,-89.7042 163.3492,-80.2728\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"164.9963,-83.3685 172.6435,-76.0357 162.0926,-76.9992 164.9963,-83.3685\"/>\n",
       "</g>\n",
       "<!-- 4927647816 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4927647816</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"254.4584,-138 134.8561,-138 134.8561,-118 254.4584,-118 254.4584,-138\"/>\n",
       "<text text-anchor=\"middle\" x=\"194.6572\" y=\"-124.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ThresholdBackward0</text>\n",
       "</g>\n",
       "<!-- 4927647816&#45;&gt;4927649664 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4927647816&#45;&gt;4927649664</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M194.6572,-117.762C194.6572,-109.185 194.6572,-96.6836 194.6572,-86.1154\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"198.1573,-86.0475 194.6572,-76.0475 191.1573,-86.0476 198.1573,-86.0475\"/>\n",
       "</g>\n",
       "<!-- 4927651400 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4927651400</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"240.6357,-206 136.6787,-206 136.6787,-186 240.6357,-186 240.6357,-206\"/>\n",
       "<text text-anchor=\"middle\" x=\"188.6572\" y=\"-192.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 4927651400&#45;&gt;4927647816 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>4927651400&#45;&gt;4927647816</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M189.5425,-185.9664C190.4199,-176.0227 191.7883,-160.5143 192.889,-148.04\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"196.3757,-148.3438 193.7683,-138.0748 189.4028,-147.7284 196.3757,-148.3438\"/>\n",
       "</g>\n",
       "<!-- 4927649552 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4927649552</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"110.8044,-280 18.5101,-280 18.5101,-248 110.8044,-248 110.8044,-280\"/>\n",
       "<text text-anchor=\"middle\" x=\"64.6572\" y=\"-266.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">model.fc_2.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"64.6572\" y=\"-254.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (128)</text>\n",
       "</g>\n",
       "<!-- 4927649552&#45;&gt;4927651400 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4927649552&#45;&gt;4927651400</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M94.0435,-247.8849C114.4463,-236.6963 141.4362,-221.8954 161.3664,-210.966\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"163.1648,-213.9715 170.25,-206.0943 159.799,-207.8338 163.1648,-213.9715\"/>\n",
       "</g>\n",
       "<!-- 4927650560 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>4927650560</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"248.4584,-274 128.8561,-274 128.8561,-254 248.4584,-254 248.4584,-274\"/>\n",
       "<text text-anchor=\"middle\" x=\"188.6572\" y=\"-260.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ThresholdBackward0</text>\n",
       "</g>\n",
       "<!-- 4927650560&#45;&gt;4927651400 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4927650560&#45;&gt;4927651400</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M188.6572,-253.9664C188.6572,-244.1231 188.6572,-228.827 188.6572,-216.4189\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.1573,-216.0748 188.6572,-206.0748 185.1573,-216.0748 192.1573,-216.0748\"/>\n",
       "</g>\n",
       "<!-- 4927650392 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>4927650392</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"237.6357,-342 133.6787,-342 133.6787,-322 237.6357,-322 237.6357,-342\"/>\n",
       "<text text-anchor=\"middle\" x=\"185.6572\" y=\"-328.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 4927650392&#45;&gt;4927650560 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>4927650392&#45;&gt;4927650560</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M186.0999,-321.9664C186.5341,-312.1231 187.209,-296.827 187.7564,-284.4189\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.2685,-284.2194 188.2128,-274.0748 184.2753,-283.9108 191.2685,-284.2194\"/>\n",
       "</g>\n",
       "<!-- 4927649496 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>4927649496</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"181.8044,-416 89.5101,-416 89.5101,-384 181.8044,-384 181.8044,-416\"/>\n",
       "<text text-anchor=\"middle\" x=\"135.6572\" y=\"-402.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">model.fc_1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"135.6572\" y=\"-390.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256)</text>\n",
       "</g>\n",
       "<!-- 4927649496&#45;&gt;4927650392 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>4927649496&#45;&gt;4927650392</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M147.5065,-383.8849C154.9066,-373.8209 164.4557,-360.8341 172.149,-350.3711\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"174.9829,-352.4253 178.0871,-342.2954 169.3433,-348.2786 174.9829,-352.4253\"/>\n",
       "</g>\n",
       "<!-- 4927649104 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>4927649104</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"271.6318,-410 199.6826,-410 199.6826,-390 271.6318,-390 271.6318,-410\"/>\n",
       "<text text-anchor=\"middle\" x=\"235.6572\" y=\"-396.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 4927649104&#45;&gt;4927650392 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>4927649104&#45;&gt;4927650392</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M228.2796,-389.9664C220.5987,-379.5204 208.4025,-362.9336 199.0206,-350.1742\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"201.8089,-348.0579 193.0652,-342.0748 196.1693,-352.2047 201.8089,-348.0579\"/>\n",
       "</g>\n",
       "<!-- 4927649608 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>4927649608</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"288.6338,-484 182.6807,-484 182.6807,-452 288.6338,-452 288.6338,-484\"/>\n",
       "<text text-anchor=\"middle\" x=\"235.6572\" y=\"-470.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">model.fc_1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"235.6572\" y=\"-458.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256, 33)</text>\n",
       "</g>\n",
       "<!-- 4927649608&#45;&gt;4927649104 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>4927649608&#45;&gt;4927649104</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M235.6572,-451.8849C235.6572,-442.5254 235.6572,-430.6379 235.6572,-420.6036\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"239.1573,-420.2954 235.6572,-410.2954 232.1573,-420.2954 239.1573,-420.2954\"/>\n",
       "</g>\n",
       "<!-- 4927649720 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>4927649720</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"342.6318,-274 270.6826,-274 270.6826,-254 342.6318,-254 342.6318,-274\"/>\n",
       "<text text-anchor=\"middle\" x=\"306.6572\" y=\"-260.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 4927649720&#45;&gt;4927651400 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>4927649720&#45;&gt;4927651400</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M289.2459,-253.9664C269.6377,-242.6667 237.5601,-224.1813 214.9085,-211.1279\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"216.5518,-208.0353 206.14,-206.0748 213.0567,-214.1003 216.5518,-208.0353\"/>\n",
       "</g>\n",
       "<!-- 4927649048 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>4927649048</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"361.6338,-348 255.6807,-348 255.6807,-316 361.6338,-316 361.6338,-348\"/>\n",
       "<text text-anchor=\"middle\" x=\"308.6572\" y=\"-334.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">model.fc_2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"308.6572\" y=\"-322.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (128, 256)</text>\n",
       "</g>\n",
       "<!-- 4927649048&#45;&gt;4927649720 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>4927649048&#45;&gt;4927649720</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M308.1833,-315.8849C307.908,-306.5254 307.5583,-294.6379 307.2632,-284.6036\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"310.7526,-284.1882 306.96,-274.2954 303.7556,-284.394 310.7526,-284.1882\"/>\n",
       "</g>\n",
       "<!-- 4927649216 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>4927649216</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"354.6318,-138 282.6826,-138 282.6826,-118 354.6318,-118 354.6318,-138\"/>\n",
       "<text text-anchor=\"middle\" x=\"318.6572\" y=\"-124.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 4927649216&#45;&gt;4927649664 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>4927649216&#45;&gt;4927649664</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M298.4585,-117.9006C278.1922,-107.7675 246.772,-92.0574 223.8068,-80.5748\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"225.3568,-77.4367 214.8473,-76.095 222.2263,-83.6977 225.3568,-77.4367\"/>\n",
       "</g>\n",
       "<!-- 4927651344 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>4927651344</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"388.8022,-212 258.5122,-212 258.5122,-180 388.8022,-180 388.8022,-212\"/>\n",
       "<text text-anchor=\"middle\" x=\"323.6572\" y=\"-198.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">model.fc_output.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"323.6572\" y=\"-186.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (4, 128)</text>\n",
       "</g>\n",
       "<!-- 4927651344&#45;&gt;4927649216 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>4927651344&#45;&gt;4927649216</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M322.4723,-179.8849C321.7767,-170.4247 320.8912,-158.382 320.1484,-148.2806\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"323.6382,-148.0118 319.4142,-138.2954 316.6571,-148.5252 323.6382,-148.0118\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x125b38c50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = agent.actor_network_main\n",
    "make_dot(model(torch.randn(1,33)), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(scores)), signal.savgol_filter(scores, 53, 3))\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrate the trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_agents = 20\n",
    "state_size = 33\n",
    "action_size = 4\n",
    "\n",
    "agent = Agent(num_instances=num_agents,\n",
    "              state_size=state_size,\n",
    "              action_size=action_size,\n",
    "              seed=0,\n",
    "              actor_hidden_sizes_list=[256, 128],\n",
    "              critic_hidden_sizes_list=[256, 128],\n",
    "              gamma=0.99,\n",
    "              num_iters_learn=1,\n",
    "              actor_lr0=0.0,\n",
    "              critic_lr0=0.0,\n",
    "              weight_decay=0.0,\n",
    "              actor_reg_loss_weight=0.0,\n",
    "              update_every=100000000,\n",
    "              noise_sigma=0.0,\n",
    "              noise_sigma_decay=0.0,\n",
    "              buffer_size=int(1e5),\n",
    "              batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_checkpoint = torch.load('checkpoints/final_checkpoint_actor.pth')\n",
    "critic_checkpoint = torch.load('checkpoints/final_checkpoint_critic.pth')\n",
    "\n",
    "agent.actor_network_main.load_state_dict(actor_checkpoint)\n",
    "agent.critic_network_main.load_state_dict(critic_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:125: RuntimeWarning: divide by zero encountered in arctanh\n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Reacher_20.app')\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "states = env_info.vector_observations            # get the current state\n",
    "score = 0\n",
    "for t in range(1000):\n",
    "    actions = agent.act(states)\n",
    "    env_info = env.step(actions)[env.brain_names[0]]        # send the actions to the environment\n",
    "    next_states = env_info.vector_observations   # get the next states\n",
    "    rewards = env_info.rewards                   # get the reward\n",
    "    dones = env_info.local_done                  # see if episode has finished\n",
    "    score += np.mean(rewards)                                # update the score\n",
    "    agent.step(states, actions, rewards, next_states, dones)\n",
    "    states = next_states                             # roll over the state to next time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
